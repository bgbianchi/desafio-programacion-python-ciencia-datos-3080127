{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3b1e230b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "import pandas as pd\n",
    "from sklearn.metrics import accuracy_score, f1_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5b34ff31",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('04_09_solicitudes.csv', delimiter=\";\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "608093bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df['Asunto']\n",
    "y = df['Categoría']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d37a3010",
   "metadata": {},
   "source": [
    "- Clasificadores Naive Bayes:\n",
    "    - Se usan para problemas de clasificación de texto de aprendizaje automático\n",
    "    - Pueden predecir  el sentimiento de un tweet, identificar el idioma de un texto o categorizar un ticket de soporte"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f18b07a",
   "metadata": {},
   "source": [
    "- Desafío: Analizar las solicitudes de soporte par predecir la categorización de solicitudes futuras\n",
    "    1. Usar la columna de Categoría como variable de destino\n",
    "    2. Usar la función train_test_split() con 20% de datos de prueba\n",
    "    3. Utilizar CountVectorizer para convertir la columna detalle en un vector de números\n",
    "    4. Guardar estos datos en una variable que será el set de datos para entrenamiento\n",
    "    5. Ajustar el modelo de clasificación\n",
    "    6. Realizar predicciones con los datos de prueba\n",
    "    7. Imprimior la información devuelta por las funciones accuracy_score y f1_score\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "058c2dd5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                     Asunto  \\\n",
      "0         Problema con el acceso web remoto   \n",
      "1                           Error de acceso   \n",
      "2              Embalaje del portátil dañado   \n",
      "3  Caducidad de las licencias empresariales   \n",
      "4                          Licencia perdida   \n",
      "\n",
      "                                         Descripción  Categoría  Urgencia  \n",
      "0  Vine aquí en busca de ayuda con respecto a la ...          4         3  \n",
      "1                 No puedo ingresar a mi computadora          4         3  \n",
      "2  Llegué a saber que el empaque estaba severamen...          1         3  \n",
      "3  Tenemos una computadora que siempre tuvo una l...          3         3  \n",
      "4  Después de un largo corte de energía perdí la ...          3         3  \n"
     ]
    }
   ],
   "source": [
    "print(df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "22583d59",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.20, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ae6f8b7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "vectorizer = CountVectorizer()\n",
    "\n",
    "X_train = vectorizer.fit_transform(X_train)\n",
    "\n",
    "# IMPORTANTE: usar transform y no fit_transform a partir de aquí al vectorizar datos, ya que el vectorizer anterior\n",
    "# ya fue entrenado y lo que queremos es realizar vectorizaciones sobre dicho modelo. En otro caso, estaríamos entrenando\n",
    "# un vectorizer diferente para cada vectorización.  \n",
    "\n",
    "X_test = vectorizer.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "5f312a56",
   "metadata": {},
   "outputs": [],
   "source": [
    "# alpha: Parámetro de suavizado (smoothing) que ayuda a evitar la probabilidad cero para palabras no vistas.\n",
    "model = MultinomialNB(alpha=1.0)\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "y_pred = model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "833193ad",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Precisión (Accuracy) del modelo: 0.67\n",
      "\n",
      "F1 Score del modelo: 0.60\n"
     ]
    }
   ],
   "source": [
    "print(f\"\\nPrecisión (Accuracy) del modelo: {accuracy_score(y_test, y_pred):.2f}\")\n",
    "print(f\"\\nF1 Score del modelo: {f1_score(y_test, y_pred, average='weighted'):.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "fc13ba29",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Predicción para 'Carpeta compartida dañada': Categoría: 1\n"
     ]
    }
   ],
   "source": [
    "nuevo_texto = [\"Carpeta compartida dañada\"]\n",
    "nuevo_texto_vectorizado = vectorizer.transform(nuevo_texto)\n",
    "prediccion_nueva = model.predict(nuevo_texto_vectorizado)\n",
    "\n",
    "print(f\"\\nPredicción para '{nuevo_texto[0]}': Categoría: {prediccion_nueva[0]}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
